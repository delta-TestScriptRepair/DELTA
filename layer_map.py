# layer_map.py

LAYER_NAME_MAP = {
    "input_object": "Input",
    "conv2D": "Conv2D",
    "conv2D_transpose": "Conv2DTranspose",
    "separable_conv2D": "SeparableConv2D",
    "separable_conv1D": "SeparableConv1D",
    "depthwise_conv2D": "DepthwiseConv2D",  # tf.keras.layers.DepthwiseConv2D
    "batch_normalization": "BatchNormalization",
    "dense": "Dense",
    "flatten": "Flatten",
    "reshape": "Reshape",
    "permute": "Permute",
    "repeat_vector": "RepeatVector",
    "zero_padding2D": "ZeroPadding2D",
    "zero_padding1D": "ZeroPadding1D",
    "cropping2D": "Cropping2D",
    "cropping1D": "Cropping1D",
    "max_pooling2D": "MaxPooling2D",
    "max_pooling1D": "MaxPooling1D",
    "average_pooling2D": "AveragePooling2D",
    "average_pooling1D": "AveragePooling1D",
    "global_max_pooling2D": "GlobalMaxPooling2D",
    "global_max_pooling1D": "GlobalMaxPooling1D",
    "global_average_pooling2D": "GlobalAveragePooling2D",
    "global_average_pooling1D": "GlobalAveragePooling1D",
    "time_distributed": "TimeDistributed",
    "activation": "Activation",  # 可加 'activation': 'linear' by default
    "softmax": "Activation",     # softmax ➝ Activation("softmax")
    "leakyReLU": "LeakyReLU",
    "ReLU": "ReLU",
    "ELU": "ELU",
    "PReLU": "PReLU",
    "thresholded_ReLU": "ThresholdedReLU",
    "simpleRNN": "SimpleRNN",
    "LSTM": "LSTM",
    "GRU": "GRU",
    "bidirectional": "Bidirectional",
    "add": "Add",
    "multiply": "Multiply",
    "dot": "Dot",
    "average": "Average",
    "maximum": "Maximum",
    "minimum": "Minimum",
    "concatenate": "Concatenate",
    "up_sampling2D": "UpSampling2D",
    "up_sampling1D": "UpSampling1D",
    "locally_connected1D": "Conv1D",
    "locally_connected2D": "Conv2D",
    "conv1D": "Conv1D",
    "convLSTM2D": "ConvLSTM2D"
}
