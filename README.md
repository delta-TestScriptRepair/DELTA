# DELTA: Automated Repair of Deep Learning Test Scripts

**DELTA (DEep Learning library Test script repAir)** is the official implementation of our ICSE 2025 paper:

> _“Automated Test Script Repair of Deep Learning Library Testing”_

DELTA automatically repairs invalid test scripts generated by DL testing tools (e.g., LEMON, MUFFIN, CEDAR), turning them into valid, executable test cases using a three-phase framework:
- **Automated Error Analysis**
- **LLM-based Script Regeneration**
- **Efficient Multi-Round Repair**

---

## Features

-  Parses raw logs and normalizes test scripts into executable Keras models
-  Uses GPT (3.5/4-turbo) to automatically fix shape/type/function errors
-  Repairs deeply nested bugs via two-round feedback repair
-  Supports batch repair via prompt reuse (1 fix → N scripts)
-  Achieves 68–100% repair success rate and up to 14.6% throughput boost

---

## Setup

```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt

Update your OpenAI API key in run.py:
api_key = "sk-..."  # or load from env

---

python run.py

This will:

Run initial error analysis and classify failures into 8 categories

Invoke GPT for batch repair per error type

Retest all models and log failures

Repeat for any remaining errors (multi-round repair)

## Project Structure
.
├── run.py                    # Entry point for the full pipeline
├── code_process.py          # Main repair loop: analysis + multi-round repair
├── input_generation.py      # GPT-driven input generation
├── test_model.py            # Model execution and validation
├── input_process.py         # Pre-process raw model + input files
├── api.py                   # Prompt templates and GPT interface
├── layer_map.py             # Mapping from DSL to Keras layer names
├── muffin_files/            # Input: raw test scripts and weights
├── input_files/             # Processed `.h5` + `.pkl` pairs
├── gpt_input/               # Invalid models awaiting repair
├── output_files/            # Successfully repaired models
├── failure_files/           # Still-invalid after repair
├── error_info.json          # Error classification log
└── requirements.txt

## Evaluation

| Tool   | LLM         | Repair Rate | Prompt Reuse |
| ------ | ----------- | ----------- | ------------ |
| LEMON  | gpt-4-turbo | 100%        | 3.77×        |
| MUFFIN | gpt-4-turbo | 76.3%       | 4.61×        |
| CEDAR  | gpt-4-turbo | 90.5%       | 3.35×        |

DELTA repairs are 2–13× faster than regeneration, with up to 14.6% increase in testing throughput.

## Citation

If you use DELTA in your research, please cite:

@inproceedings{delta2025,
  title={Automated Test Script Repair of Deep Learning Library Testing},
  author={Anonymous},
  booktitle={ICSE},
  year={2025}
}
